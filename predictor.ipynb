{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved encoder model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import Lang, ToxicityDataset, collate, normalizeString\n",
    "\n",
    "lang = Lang(\"eng\")\n",
    "data = pd.read_csv('data/train_2024.csv', quoting = 3)\n",
    "df = pd.DataFrame(data)\n",
    "for sentence in df['text']:\n",
    "    lang.addSentence(normalizeString(sentence))   \n",
    "\n",
    "trainset = ToxicityDataset('data/train_2024.csv', 'id', 'text', 'label', lang)\n",
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./test_data.csv', quoting = 3)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "for sentence in test_df['text']:\n",
    "    lang.addSentence(normalizeString(sentence))\n",
    "\n",
    "testset = ToxicityDataset('./test_data.csv', 'id', 'text', 'label', lang)\n",
    "test_loader = DataLoader(testset, batch_size=1, shuffle=False, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the saved encoder model\n",
    "from encoder import EncoderClassifier, Encoder, MLPClassifier\n",
    "\n",
    "embed_size = 256\n",
    "bert_encoder = Encoder(src_vocab_size=trainset.lang.n_words, n_blocks = 3, n_features = embed_size, n_heads = 4, n_hidden = 512, dropout = 0.1, max_length = 5000)\n",
    "classifier = MLPClassifier(n_features = embed_size, num_classes = 2, num_layers = 2, dropout = 0.1)\n",
    "model = EncoderClassifier(bert_encoder, classifier)\n",
    "model.load_state_dict(torch.load('encoder.pth', map_location = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n",
      "11000\n",
      "11200\n",
      "11400\n",
      "11600\n",
      "11800\n"
     ]
    }
   ],
   "source": [
    "predictions = pd.DataFrame(columns = ['id', 'label'])\n",
    "model.eval()\n",
    "\n",
    "predicted = torch.tensor([]).to(device)\n",
    "translations = []\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, mask, labels = data\n",
    "    \n",
    "    #translated = [testset.lang.index2word[i.item()] for input in inputs for i in input]\n",
    "    #translations.append(translated)\n",
    "    inputs = inputs.to(device)\n",
    "    mask = mask.to(device)\n",
    "    \n",
    "    outputs = model(inputs, mask)\n",
    "\n",
    "    pre = torch.round(torch.sigmoid(outputs))\n",
    "    predicted = torch.cat((predicted, pre), dim = 0)\n",
    "    if i % 200 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11929, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = predicted.squeeze().detach().numpy().astype(int)\n",
    "predictions['label'] = predicted\n",
    "predictions['id'] = test_data['id']\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('predictions.csv', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
